{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About TensorFlow and Deep Learning:-\n",
    "\n",
    "**TensorFlow:** A Python library that is used for modelling/implementation of deep learning models/networks. TensorFlow = Tensors + Flow. Tensor corresponds to the way data is represented in this library and Flow depicts the flow of these Tensors through the <i>computation graph</i>.\n",
    "\n",
    "A <i>computation graph</i> is series of TensorFlow operations arranged into a graph of nodes.\n",
    "\n",
    "**Tensors**: The standard way of representing data in TensorFlow. Tensors are nothing but multidimensional arrays, an extension of matrices (2D tables) to data with higher dimensions.\n",
    "\n",
    "Note: Only tensors may be passed between nodes in a computation graph.\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li> Dimensionality is measured as **Ranks**:-\n",
    "\n",
    "<ol>\n",
    "    \n",
    "   <li> Rank 0 -> a Scalar, example: s = 482\n",
    "\n",
    "   <li> Rank 1 -> a Vector, example: v = [1, 2, 3]\n",
    "\n",
    "   <li> Rank 2 -> a Matrix, example: m = [[1,5,6], [2,5,6], [3,5,6]]\n",
    "\n",
    "   <li> Rank 3 -> a 3-Tesor or a cube holding some data, example: t = [[[1,5,6], [2,5,6], [3,5,6]], [[1,5,6], [2,5,6], [3,5,6]], [[1,5,6], [2,5,6], [3,5,6]]]\n",
    "    \n",
    "</ol>\n",
    "\n",
    "    ...\n",
    "\n",
    "   ** Rank n -> n-Tensor **\n",
    "\n",
    "<li> Tensor Data Types:- \n",
    "\n",
    "Tensorflow automattically assigns the correct data type. If you want to specifically assign the data type in order to save memory or do some other operation, it is possible.\n",
    "\n",
    "<ol>\n",
    "  \n",
    "   <li> DT_FLOAT -> tf.float32\n",
    "    \n",
    "   <li> DT_DOUBLE-> tf.float64\n",
    "    \n",
    "   <li> DT_INT8 -> tf.int8\n",
    "\n",
    "   <li> DT_UINT8 -> tf.uint8\n",
    "    \n",
    "   ...\n",
    "    \n",
    "   <li> DT_INT64 -> tf.int64\n",
    "    \n",
    "   <li> DT_STRING -> tf.string\n",
    "    \n",
    "   <li> DT_BOOL -> tf.bool\n",
    "    \n",
    "</ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorFlow Coding structure**\n",
    "\n",
    "It consists of two sections in particular:-\n",
    "\n",
    "<ul>\n",
    "    <li> Building a computation graph.\n",
    "    <li> Running the computation graph.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1** - Building a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32) Tensor(\"mul:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Import the TensorFlow library\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Defining two constant nodes\n",
    "aNode = tf.constant(5.0)\n",
    "bNode = tf.constant(1.9, tf.float32)\n",
    "\n",
    "cNode = aNode*bNode;\n",
    "\n",
    "# At this point, they are just abstract Tensors and not actual calculations are running.\n",
    "# Only operations are created.\n",
    "print (aNode, bNode, cNode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2** - Running a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 1.9]\n",
      "9.5\n"
     ]
    }
   ],
   "source": [
    "# To execute the graph, we run it inside a session\n",
    "# A session places graph operations onto devices such as CPU/GPU.\n",
    "\n",
    "''' Method 1 '''\n",
    "\n",
    "aSession = tf.Session()\n",
    "\n",
    "print (aSession.run([aNode, bNode]))\n",
    "# You need to close a session in order to free up the resources it used.\n",
    "aSession.close()\n",
    "\n",
    "''' Method 2 '''\n",
    "\n",
    "with tf.Session() as bSession:\n",
    "    # You just need to run the output Tensor\n",
    "    output = bSession.run(cNode)\n",
    "    print (output)\n",
    "bSession.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing TensorFlow: TensorBoard**\n",
    "\n",
    "TensorBoard is a suite of web-applications for understanding your Tensor graphs.\n",
    "\n",
    "The most convinient way to do this is using FileWriter by:     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aNode = tf.constant(5.0)\n",
    "bNode = tf.constant(1.9, tf.float32)\n",
    "cNode = aNode*bNode;\n",
    "\n",
    "with tf.Session() as bSession:\n",
    "    output = bSession.run(cNode)    \n",
    "    # Give the first argument as a path and the second as the graph of the session\n",
    "    aFileWriter = tf.summary.FileWriter('aSimpleGraph', aSession.graph)\n",
    "bSession.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After writing the log, go to the directory in your command line and type:\n",
    "\n",
    "   ** tensorboad --logdir=\"TensorFlow\" **\n",
    "   \n",
    "It will say that the TensorBoard runs at http://localhost:6006/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have been seeing constant nodes in the previous examples. Let us dig deeper into them and other nodes in TensorFlow\n",
    "\n",
    "**1. Constants**: As the name suggests, they have hardcoded values and take in no inputs. All they do is output this internal value in an active session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Placeholders**: These nodes are able to take in external input, assuming that they will be provided one at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  [[0.09628455 0.04013548]] \n",
      "B:  [[0.9588434 0.2384872]] \n",
      "A+B:  [[1.055128  0.2786227]]\n",
      "\n",
      "X: [[0.17665679 0.92436702 0.03543605 ... 0.22319722 0.97795651 0.16782616]\n",
      " [0.37308356 0.27207303 0.44560627 ... 0.04632262 0.70691266 0.66263241]\n",
      " [0.19653761 0.20654682 0.39907982 ... 0.59950445 0.16686145 0.29342747]\n",
      " ...\n",
      " [0.56601218 0.09143504 0.61979671 ... 0.48119927 0.10804474 0.74068156]\n",
      " [0.70787955 0.5259055  0.43678699 ... 0.02699478 0.95645921 0.28866577]\n",
      " [0.19381777 0.24777248 0.73393277 ... 0.5931318  0.57560468 0.51895267]] \n",
      "X*X: [[261.33505 257.94604 257.83853 ... 256.2542  266.19772 263.08475]\n",
      " [260.25317 255.72462 256.71622 ... 253.58792 262.6249  254.52263]\n",
      " [269.83893 264.357   264.67615 ... 261.75647 271.45398 262.81573]\n",
      " ...\n",
      " [268.61176 263.1862  267.73013 ... 263.42484 268.1549  258.25046]\n",
      " [254.83615 245.73447 245.3367  ... 243.03151 246.2926  242.38742]\n",
      " [264.4721  251.63567 254.13    ... 259.0703  254.8607  252.34216]]\n"
     ]
    }
   ],
   "source": [
    "aNode = tf.placeholder(tf.float32)\n",
    "bNode = tf.placeholder(tf.float32)\n",
    "\n",
    "summedNode = aNode + bNode;\n",
    "# You can also use the in-build TensorFlow operations\n",
    "# summedNode = tf.add(aNode, bNode);\n",
    "\n",
    "xNode = tf.placeholder(tf.float32, shape=(1024, 1024))\n",
    "# matmul is the in-built TensorFlow operation for matrix-multiplication\n",
    "yNode = tf.matmul(xNode, xNode)\n",
    "\n",
    "with tf.Session() as aSession:\n",
    "    # ERROR: will fail because placeholder was not fed.\n",
    "    #output = aSession.run(summedNode);\n",
    "    #output = aSession.run(summedNode);\n",
    "\n",
    "    # This will succeed.\n",
    "    randArrayA = np.random.rand(1, 2)\n",
    "    randArrayB = np.random.rand(1, 2)\n",
    "    output = aSession.run(summedNode, feed_dict={aNode: randArrayA, bNode: randArrayB});\n",
    "    print (\"A: \",randArrayA, \"\\nB: \", randArrayB, \"\\nA+B: \",output)\n",
    "    \n",
    "    randArrayX = np.random.rand(1024, 1024)\n",
    "    print(\"\\nX:\", randArrayX, \"\\nX*X:\", aSession.run(yNode, feed_dict={xNode: randArrayX}))  # Will succeed.\n",
    "aSession.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "**3. Variables**: Used to integrate trainable parameters to the graph. The weights and the offset are the best examples of variables. Here is an example of variable usage in training a model:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([0.9999908], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "W = tf.Variable([.30], tf.float32)\n",
    "b = tf.Variable([-.30], tf.float32)\n",
    "\n",
    "# input and output variables\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "linearModel = W*x + b\n",
    "\n",
    "# Loss (this will tell us how far we are from getting to the right answer)\n",
    "squaredDelta = tf.square(linearModel - y)\n",
    "loss = tf.reduce_sum(squaredDelta)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# Initialize all the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "'''\n",
    "An Optimizer modifies each variable according to the magnitude of the derivate of the\n",
    "loss with respect to that variable. Gradient Descent is a type of Optimizer.\n",
    "\n",
    "Gradient Descent:-\n",
    "\n",
    "Suppose there is a Hiker are on the top of a mountain in a mountain range. The Hiker is blindfolded and\n",
    "he wants to reach the ground. He starts moving in the direction that takes him lower until it starts\n",
    "going up again.\n",
    "\n",
    "Hence, the Position of hiker is weight. Length of the step is the learning rate.\n",
    "\n",
    "OR in other words:\n",
    "\n",
    "An Optimizer will calculate the change in the loss WRT to change in the variable. If the loss is \n",
    "decreasing then it will continue changing the varibale in that direction.\n",
    "'''\n",
    "\n",
    "with tf.Session() as someSession:\n",
    "    someSession.run(init)\n",
    "\n",
    "    for i in range(1000):\n",
    "        someSession.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "    print (someSession.run([W, b]))\n",
    "someSession.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a classifier using what we have learned/used so far**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: (Binary Classificatoin) Given some training data with n features and corresponding labels (0 or 1), train a binary classifier and predict the labels on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1_home_win</th>\n",
       "      <th>team1_home_draw</th>\n",
       "      <th>team1_away_win</th>\n",
       "      <th>team1_away_draw</th>\n",
       "      <th>team1_home_goals</th>\n",
       "      <th>team1_away_goals</th>\n",
       "      <th>team1_home_goals_conceded</th>\n",
       "      <th>team1_away_goals_conceded</th>\n",
       "      <th>...</th>\n",
       "      <th>away_player_4</th>\n",
       "      <th>away_player_5</th>\n",
       "      <th>away_player_6</th>\n",
       "      <th>away_player_7</th>\n",
       "      <th>away_player_8</th>\n",
       "      <th>away_player_9</th>\n",
       "      <th>away_player_10</th>\n",
       "      <th>away_player_11</th>\n",
       "      <th>home_team_overall</th>\n",
       "      <th>away_team_overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.647059</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>61</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>59</td>\n",
       "      <td>429</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>1.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>76</td>\n",
       "      <td>395</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.302632</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.342105</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.710526</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>59</td>\n",
       "      <td>58</td>\n",
       "      <td>73</td>\n",
       "      <td>61</td>\n",
       "      <td>63</td>\n",
       "      <td>429</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "      <td>68</td>\n",
       "      <td>81</td>\n",
       "      <td>57</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>459</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>1.590909</td>\n",
       "      <td>1.015385</td>\n",
       "      <td>1.287879</td>\n",
       "      <td>1.661538</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>58</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>77</td>\n",
       "      <td>430</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   team1  team2  team1_home_win  team1_home_draw  team1_away_win  \\\n",
       "0      4      7        0.472222         0.277778        0.147059   \n",
       "1      9     19        0.277778         0.444444        0.117647   \n",
       "2      4      3        0.447368         0.302632        0.171053   \n",
       "3     24      6        0.000000         0.500000        0.500000   \n",
       "4     20     16        0.393939         0.318182        0.230769   \n",
       "\n",
       "   team1_away_draw  team1_home_goals  team1_away_goals  \\\n",
       "0         0.323529          1.250000          0.735294   \n",
       "1         0.117647          0.888889          0.529412   \n",
       "2         0.250000          1.342105          0.684211   \n",
       "3         0.000000          1.500000          1.500000   \n",
       "4         0.276923          1.590909          1.015385   \n",
       "\n",
       "   team1_home_goals_conceded  team1_away_goals_conceded        ...          \\\n",
       "0                   0.944444                   1.647059        ...           \n",
       "1                   1.055556                   1.882353        ...           \n",
       "2                   0.973684                   1.710526        ...           \n",
       "3                   2.000000                   2.500000        ...           \n",
       "4                   1.287879                   1.661538        ...           \n",
       "\n",
       "   away_player_4  away_player_5  away_player_6  away_player_7  away_player_8  \\\n",
       "0             65             69             61             72             58   \n",
       "1             76             69             60             62             67   \n",
       "2             56             68             70             59             58   \n",
       "3             76             64             73             68             81   \n",
       "4             55             58             78             80             67   \n",
       "\n",
       "   away_player_9  away_player_10  away_player_11  home_team_overall  \\\n",
       "0             71              72              59                429   \n",
       "1             81              69              76                395   \n",
       "2             73              61              63                429   \n",
       "3             57              69              65                459   \n",
       "4             75              60              77                430   \n",
       "\n",
       "   away_team_overall  \n",
       "0                431  \n",
       "1                420  \n",
       "2                467  \n",
       "3                501  \n",
       "4                370  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  109\n",
      "Number of labels:  3\n",
      "WARNING:tensorflow:From <ipython-input-1-bcfa5aeb21a8>:127: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "\n",
      "epoch:  1  Acc:  0.2890625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bcfa5aeb21a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0msomeSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msomeSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mcost_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mcorrectPred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def readData():\n",
    "    # Read the training data and separate the dependent variable from the features\n",
    "    trainDataFrame = pd.read_csv(\"final_processed_2.csv\")\n",
    "    \n",
    "    # df.columns is zero-based pd.Index\n",
    "    X = trainDataFrame.drop(['div','FTR', 'key', 'date', 'WHH','WHD','WHA'], axis=1)\n",
    "    y = trainDataFrame['FTR']\n",
    "    \n",
    "#     nCols = len(trainDataFrame.columns)\n",
    "    \n",
    "#     X = trainDataFrame[trainDataFrame.columns[0:nCols-1]].values\n",
    "#     y = trainDataFrame[trainDataFrame.columns[nCols-1]].values\n",
    "    \n",
    "    # Encoding the dependent variable\n",
    "    # Incase of labels such as \"Yes\" and \"No\", we want to map them to a corresponding label vector\n",
    "    # that has all zeroes expect at the corresponding label.\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    Y = one_hot_encode(y)\n",
    "    \n",
    "\n",
    "    display(X.head())\n",
    "    \n",
    "    return (X, Y)\n",
    "    \n",
    "def one_hot_encode(labels):\n",
    "    nLabels = len(labels)\n",
    "    nUniqueLabels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((nLabels, nUniqueLabels))\n",
    "    one_hot_encode[np.arange(nLabels), labels] = 1\n",
    "    return one_hot_encode\n",
    "    \n",
    "    \n",
    "X, Y = readData()\n",
    "X, Y = shuffle(X, Y, random_state=1)\n",
    "\n",
    "# print (Y)\n",
    "\n",
    "# Dividing the training data into train and dev sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size = 0.2, )#random_state = 415)\n",
    "\n",
    "# print (train_y)\n",
    "\n",
    "# Inspect the shape after dividing into the right data sets\n",
    "# print ((train_x.shape))\n",
    "# print ((test_x.shape))\n",
    "# print ((train_y.shape))\n",
    "# print ((test_y.shape))\n",
    "\n",
    "# Important parameters and modelling variables\n",
    "learning_rate = 0.1\n",
    "training_epochs = 1000\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "\n",
    "# dimension of the feature vector\n",
    "n_dim = X.shape[1]\n",
    "print (\"Number of features: \", n_dim)\n",
    "# Number of possible labels / output classes\n",
    "n_class = Y.shape[1]\n",
    "print (\"Number of labels: \", n_class)\n",
    "\n",
    "# Define the number of hidden layers and Neurons in each layer\n",
    "n_hidden_1 = 40\n",
    "n_hidden_2 = 30\n",
    "n_hidden_3 = 40\n",
    "n_hidden_4 = 40\n",
    "\n",
    "# input and output variables\n",
    "x = tf.placeholder(tf.float32, [None, n_dim]) # 'None' tells that it can be any value\n",
    "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32, [None, n_class]) # 'None' tells that it can be any value\n",
    "\n",
    "# Defining the model\n",
    "def multiLayerPerceptron(x, weights, biases):\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights[\"h1\"]), biases[\"b1\"])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights[\"h2\"]), biases[\"b2\"])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights[\"h3\"]), biases[\"b3\"])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights[\"h4\"]), biases[\"b4\"])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    layer_out = tf.matmul(layer_4, weights[\"out\"]) + biases[\"out\"]\n",
    "    \n",
    "    return layer_out\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    \"h4\": tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    \"out\": tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    \"b4\": tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    \"out\": tf.Variable(tf.truncated_normal([n_class]))\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize all the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "y = multiLayerPerceptron(x, weights, biases)\n",
    "\n",
    "costFunction = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y,labels=y_))\n",
    "trainingStep = tf.train.GradientDescentOptimizer(learning_rate).minimize(costFunction)\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "\n",
    "mseHistory = []\n",
    "accHistory = []\n",
    "\n",
    "someSession = tf.Session()\n",
    "someSession.run(init)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    someSession.run(trainingStep, feed_dict={x: train_x, y_: train_y})\n",
    "    cost = someSession.run(trainingStep, {x: train_x, y_: train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correctPred = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "\n",
    "    pred_y = someSession.run(y, {x: test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = someSession.run(mse)\n",
    "    mseHistory.append(mse_)\n",
    "    acc = (someSession.run(acc, {x: train_x, y_: train_y}))\n",
    "    accHistory.append(acc)\n",
    "\n",
    "    if (epoch % 100 == 1):\n",
    "        print (\"\\nepoch: \", epoch, \" Acc: \", acc)\n",
    "        \n",
    "# save_path = saver.save(someSession, )\n",
    "someSession.close()\n",
    "\n",
    "print (mseHistory)\n",
    "print (accHistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
